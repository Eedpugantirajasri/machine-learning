{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6n4DFrs1GJxKeo/6bWHCy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FaP8uN_UURo9","executionInfo":{"status":"ok","timestamp":1743745352629,"user_tz":-330,"elapsed":39584,"user":{"displayName":"rajasri eedpuganti","userId":"07407753091693883990"}},"outputId":"49fe9b66-b6b2-472d-f4c3-018104e4c5a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6175\n","Precision: 0.6960\n","Recall: 0.6175\n"]}],"source":["from sklearn.datasets import fetch_20newsgroups\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn import metrics\n","# Load the 20 newsgroups dataset\n","newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(newsgroups.data, newsgroups.target,\n","test_size=0.2, random_state=42)\n","# Vectorize the text data\n","vectorizer = CountVectorizer()\n","X_train_vec = vectorizer.fit_transform(X_train)\n","X_test_vec = vectorizer.transform(X_test)\n","# Train the Naive Bayes Classifier\n","nb_classifier = MultinomialNB()\n","nb_classifier.fit(X_train_vec, y_train)\n","# Make predictions\n","y_pred = nb_classifier.predict(X_test_vec)\n","# Calculate Accuracy, Precision, and Recall\n","accuracy = metrics.accuracy_score(y_test, y_pred)\n","precision = metrics.precision_score(y_test, y_pred, average='weighted')\n","recall = metrics.recall_score(y_test, y_pred, average='weighted')\n","# Print the results\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")"]}]}